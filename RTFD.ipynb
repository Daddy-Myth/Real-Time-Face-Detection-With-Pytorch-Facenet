{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6d3d372-cd88-4a75-9b29-a0c26daefc95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install torch facenet-pytorch tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d4c388-e7a8-4745-8ed7-379e7a670242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "from tqdm import tqdm\n",
    "from types import MethodType\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa013226-9278-4fcf-a115-f04f0eda4154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(img):\n",
    "    res = resnet(torch.Tensor(img))\n",
    "    return res\n",
    "def detect_box(self, img, save_path = None):\n",
    "    #Detect faces\n",
    "    batch_boxes, batch_probs, batch_points = self.detect(img, landmarks = True)\n",
    "    #select faces\n",
    "    if not self.keep_all:\n",
    "        batch_boxes, batch_probs, batch_points = self.select_boxes(\n",
    "            batch_boxes, batch_probs, batch_points, img, method = self.selection_method\n",
    "        )\n",
    "    #Extract faces\n",
    "    faces = self.extract(img, batch_boxes, save_path)\n",
    "    return batch_boxes, faces\n",
    "# load model\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "mtcnn = MTCNN(\n",
    "    image_size = 224, keep_all = True, thresholds = [0.4, 0.5, 0.5], min_face_size = 60\n",
    ")\n",
    "mtcnn.detect_box = MethodType(detect_box, mtcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7d11b6-5e8d-4e26-8cb7-c727456522ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get encoded features for all saved images\n",
    "saved_pictures = \"./Saved/\"\n",
    "all_people_faces = {}\n",
    "\n",
    "'''for file in person_face, extension = file.split(\".\")\n",
    "    img = cv2.imread(f\"{saved_pictures}/{person_face}.jpg\")\n",
    "    cropped = mtcnn(img)\n",
    "    if cropped is not None:\n",
    "        all_people_faces[person_face] = encode(cropped)[0, :1]'''\n",
    "for file in os.listdir(saved_pictures):\n",
    "    if file.endswith('.jpg') or file.endswith('.png'):\n",
    "        person_face = os.path.splitext(file)[0]\n",
    "        image_path = os.path.join(saved_pictures, file)\n",
    "\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            continue \n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        cropped = mtcnn(img_rgb)\n",
    "\n",
    "        if cropped is not None:\n",
    "            if len(cropped.shape) == 3:\n",
    "                cropped = cropped.unsqueeze(0) # add batch dim\n",
    "\n",
    "            embedding = encode (cropped).detach()\n",
    "            all_people_faces[person_face] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483b2f2f-0e4f-4b6c-a44d-30fafa9dbb4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_people_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b74d08-0f69-48af-8521-f7cdeeda4c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(cam = 0, thres = 0.7):\n",
    "    vdo = cv2.VideoCapture(cam)\n",
    "\n",
    "    # Initialize time for FPS calculation\n",
    "    prev_time = time.time()\n",
    "    \n",
    "    while vdo.grab():\n",
    "        _, img0 = vdo.retrieve()\n",
    "        batch_boxes, cropped_images = mtcnn.detect_box(img0)\n",
    "    \n",
    "        if cropped_images is not None:\n",
    "            for box, cropped in zip(batch_boxes, cropped_images):\n",
    "                x, y, x2, y2 = [int(x) for x in box]\n",
    "                if len(cropped.shape) == 3:\n",
    "                    cropped = cropped.unsqueeze(0)\n",
    "                img_embedding = encode(cropped)\n",
    "                \n",
    "                detect_dict= {}\n",
    "                for k, v in all_people_faces.items():\n",
    "                    detect_dict[k] = (v - img_embedding).norm().item()\n",
    "\n",
    "                min_key = min(detect_dict, key = detect_dict.get)\n",
    "                if detect_dict[min_key] >= thres:\n",
    "                    min_key = 'Undetected'\n",
    "    \n",
    "                cv2.rectangle(img0, (x, y), (x2, y2), (0,0,255), 2)\n",
    "                cv2.putText(\n",
    "                    img0, min_key, (x+5, y+10),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 0.5, (255,255,255), 1)\n",
    "    \n",
    "        # ==== FPS Calculation and Display ====\n",
    "        curr_time = time.time()\n",
    "        fps = 1 / (curr_time - prev_time)\n",
    "        prev_time = curr_time\n",
    "\n",
    "        # Show FPS on the top-left of the screen\n",
    "        cv2.putText(\n",
    "            img0, f\"FPS: {fps:.2f}\", (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2\n",
    "        )\n",
    "        # display\n",
    "        cv2.imshow('output', img0)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "if __name__ == '__main__':\n",
    "    detect(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd41ea2f-3b0e-403d-b290-55f6f9532f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09525af8-f5bf-45a8-abac-a01a4e26918c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
